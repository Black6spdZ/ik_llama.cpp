name: IK-Llama-Epyc-5070Ti-Blackwell-Native
on: workflow_dispatch

jobs:
  build-windows:
    runs-on: windows-latest
    steps:
    - name: Checkout Code (Iwan's Fork)
      uses: actions/checkout@v4
      with:
        repository: ikawrakow/ik_llama.cpp
        ref: main
        submodules: recursive
        fetch-depth: 0

    - name: Install CUDA Toolkit 13.1
      uses: Jimver/cuda-toolkit@v0.2.30  # Check for latest action version
      with:
        cuda: '13.1.0'                   # CRITICAL: Targets Blackwell Native
        method: 'network'

    - name: Setup MSVC
      uses: ilammy/msvc-dev-cmd@v1

    - name: Configure CMake (Blackwell sm_120 Optimized)
      shell: cmd
      run: |
        cmake -B build -G "Visual Studio 17 2022" -A x64 ^
          -DGGML_CUDA=ON ^
          -DCMAKE_CUDA_ARCHITECTURES="86;89;120" ^
          -DGGML_CUDA_F16=ON ^
          -DGGML_CUDA_FORCE_MMQ=OFF ^
          -DGGML_FLASH_ATTN=ON ^
          -DGGML_CUDA_FA_ALL_QUANTS=ON ^
          -DGGML_IQK_FA_ALL_QUANTS=ON ^
          -DGGML_STATIC=ON ^
          -DBUILD_SHARED_LIBS=OFF ^
          -DCUDAToolkit_ROOT="%CUDA_PATH%" ^
          -DCMAKE_CUDA_FLAGS="-cudart static" ^
          -DLLAMA_NATIVE=OFF ^
          -DGGML_AVX2=ON ^
          -DGGML_FMA=ON ^
          -DGGML_F16C=ON ^
          -DGGML_AVX512=OFF ^
          -DCMAKE_CUDA_COMPILER="%CUDA_PATH%/bin/nvcc.exe" ^
          -DLLAMA_LTO=OFF ^
          -DGGML_LTO=OFF ^
          -DGGML_BUILD_TESTS=OFF ^
          -DGGML_BUILD_EXAMPLES=OFF ^
          -DLLAMA_CURL=OFF

    - name: Build ik_llama (Parallel)
      run: cmake --build build --config Release --target llama-server -j 8

    - name: Upload Artifact
      uses: actions/upload-artifact@v4
      with:
        name: ik-llama-epyc-blackwell
        path: build/bin/Release/*.exe
